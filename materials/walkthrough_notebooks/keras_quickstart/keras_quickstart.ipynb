{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae52109f",
   "metadata": {},
   "source": [
    "<a id = 'top'></a>\n",
    "\n",
    "# A quick-start guide to Keras\n",
    "  * A. [What is Keras?](#introToKeras) \n",
    "  * B. [Basic Operations](#kerasBasicOps)  \n",
    "      * 1. [Sequential interface](#sequentialInterface)\n",
    "      * 2. [Creating a model](#createModel)\n",
    "      * 3. [Compiling a model](#compileModel)\n",
    "      * 4. [Training a model](#trainModel)\n",
    "      * 5. [Saving a model](#saveModel)\n",
    "      * 6. [Reloading a model](#reloadModel)\n",
    "  * C. [Defining your model inside a function to add flexibility](#functionWrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40381e7",
   "metadata": {},
   "source": [
    "[Return to Top](#top)\n",
    "<a id = 'introToKeras'></a>\n",
    "## A. What is Keras?\n",
    "\n",
    "[Keras](https://en.wikipedia.org/wiki/Keras) is a front-end interface to Tensorflow.  Keras has its own [documentation](https://keras.io/about/) and is also well-documented in [tensorflow keras documentation](https://www.tensorflow.org/api_docs/python/tf/keras).  \n",
    "\n",
    "Using the Keras interface greatly simplifies the task of constructing, training and using tensorflow models.  In this notebook we'll build and train a basic fully-connected neural net and learn some of the important operations available within Keras.  We'll use the [sequential-model syntax](https://keras.io/guides/sequential_model/), which is useful when becoming familiar with Keras and appropriate for models where each layer has a single output feeding sequentially to the next layer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9968fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0-rc0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7173c3af",
   "metadata": {},
   "source": [
    "[Return to Top](#top)\n",
    "<a id = 'kerasBasicOps'></a>\n",
    "## B. Basic Operations in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9478a88b",
   "metadata": {},
   "source": [
    "1. Construct the model graph from model input, model layers\n",
    "2. Build the model (from input, output of the graph)\n",
    "3. Compile the model with optimizer, metric set, loss function\n",
    "4. Fit the model / evaluate the model\n",
    "5. Save the model and re-use the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa486a4",
   "metadata": {},
   "source": [
    "[Return to Top](#top)\n",
    "<a id = 'sequentialInterface'></a>\n",
    "### B1. Sequential interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9745fe1a",
   "metadata": {},
   "source": [
    "[Return to Top](#top)\n",
    "<a id = 'createModel'></a>\n",
    "### B2. Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec176bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-14 17:35:09.316846: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "hidden_units = 200\n",
    "model = keras.Sequential(\n",
    "    [keras.Input(shape=(2,)),\n",
    "     keras.layers.Dense(200, activation=\"relu\", name=\"h1_layer\"),\n",
    "     keras.layers.Dense(100, activation=\"relu\", name=\"h2_layer\"),\n",
    "     keras.layers.Dense(2, activation=\"sigmoid\", name=\"output_layer\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4473899d",
   "metadata": {},
   "source": [
    "[Return to Top](#top)\n",
    "<a id = 'compileModel'></a>\n",
    "### B3. Compiling a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9a9e729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function, optimizer, and accuracy\n",
    "# Here we're using some basic loss, optimizer, metrics provided by Keras, all of which use reasonable defaults.\n",
    "\n",
    "# However if you want to adjust things like learning rate you'll want to use the full Keras functional version of these to have ability to change\n",
    "# ... the arguments from their default values.\n",
    "\n",
    "loss = \"sparse_categorical_crossentropy\"    # Using sparse crossentropy when your class values are defined by unique labels.  Alternatively, using\n",
    "#                                             ...categorical_crossentropy requires your labels to be in one-hot vector format.\n",
    "optimizer = \"adam\"       # adam is an optimizer we'll use a lot\n",
    "metrics = [\"sparse_categorical_accuracy\"] # This is a better accuracy metric to use\n",
    "# ...as there is a bug in \"accuracy\" metric preventing re-loaded model from calculating \n",
    "# ...correct accuracy\n",
    "\n",
    "model.compile(loss = loss, optimizer = optimizer, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72770e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " h1_layer (Dense)            (None, 200)               600       \n",
      "                                                                 \n",
      " h2_layer (Dense)            (None, 100)               20100     \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,902\n",
      "Trainable params: 20,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Always good to display your model and make sure its dimensions are what you expect\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9030fce-6c4d-4ffd-b184-ed573acfc7af",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /Users/jun/.pyenv/versions/miniforge3-4.10.3-10/envs/nlp/lib/python3.10/site-packages (from pydot) (3.0.6)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-1.4.2\n",
      "Running `brew update --preinstall`...\n",
      "\u001b[34m==>\u001b[0m \u001b[1mAuto-updated Homebrew!\u001b[0m\n",
      "Updated 4 taps (homebrew/core, homebrew/cask, dart-lang/dart and sass/sass).\n",
      "\u001b[34m==>\u001b[0m \u001b[1mNew Formulae\u001b[0m\n",
      "pinot                                    zk\n",
      "\u001b[34m==>\u001b[0m \u001b[1mUpdated Formulae\u001b[0m\n",
      "Updated 189 formulae.\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRenamed Formulae\u001b[0m\n",
      "annie -> lux\n",
      "\u001b[34m==>\u001b[0m \u001b[1mNew Casks\u001b[0m\n",
      "fishing-funds\n",
      "\u001b[34m==>\u001b[0m \u001b[1mUpdated Casks\u001b[0m\n",
      "Updated 114 casks.\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDeleted Casks\u001b[0m\n",
      "aio-creator-neo            pixelpeeper                web-sharing\n",
      "aleo-studio                rcse                       wwdcsrt\n",
      "art-directors-toolkit      sickbeard-anime            zoolz\n",
      "getrasplex                 tranquility\n",
      "omx-ebooks                 trayplay\n",
      "\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/gd/manifests/2.3.3_1\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/gd/blobs/sha256:8976ef6710a704e\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/jasper/manifests/2.0.33\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/jasper/blobs/sha256:7f5cd02f1f3\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/netpbm/manifests/10.86.27\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/netpbm/blobs/sha256:bf05a65228f\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/gts/manifests/0.7.6_2\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/gts/blobs/sha256:7a4a3f88060046\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/gdk-pixbuf/manifests/2.42.6\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/gdk-pixbuf/blobs/sha256:d8984c0\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/pango/manifests/1.50.3\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/pango/blobs/sha256:135a1cdcbc6e\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/librsvg/manifests/2.50.7\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/librsvg/blobs/sha256:3753625c61\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/graphviz/manifests/2.50.0\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/graphviz/blobs/sha256:3b342e857\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading from https://pkg-containers.githubusercontent.com/ghcr1/blobs/sh\u001b[0m\n",
      "######################################################################## 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling dependencies for graphviz: \u001b[32mgd\u001b[39m, \u001b[32mjasper\u001b[39m, \u001b[32mnetpbm\u001b[39m, \u001b[32mgts\u001b[39m, \u001b[32mgdk-pixbuf\u001b[39m, \u001b[32mpango\u001b[39m and \u001b[32mlibrsvg\u001b[39m\u001b[0m\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling graphviz dependency: \u001b[32mgd\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring gd--2.3.3_1.monterey.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /usr/local/Cellar/gd/2.3.3_1: 33 files, 1.4MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling graphviz dependency: \u001b[32mjasper\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring jasper--2.0.33.monterey.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /usr/local/Cellar/jasper/2.0.33: 41 files, 1.3MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling graphviz dependency: \u001b[32mnetpbm\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring netpbm--10.86.27.monterey.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /usr/local/Cellar/netpbm/10.86.27: 410 files, 17.8MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling graphviz dependency: \u001b[32mgts\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring gts--0.7.6_2.monterey.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /usr/local/Cellar/gts/0.7.6_2: 26 files, 1.4MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling graphviz dependency: \u001b[32mgdk-pixbuf\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring gdk-pixbuf--2.42.6.monterey.bottle.tar.gz\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1m/usr/local/Cellar/gdk-pixbuf/2.42.6/bin/gdk-pixbuf-query-loaders --update-ca\u001b[0m\n",
      "ðŸº  /usr/local/Cellar/gdk-pixbuf/2.42.6: 147 files, 3.7MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling graphviz dependency: \u001b[32mpango\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring pango--1.50.3.monterey.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /usr/local/Cellar/pango/1.50.3: 67 files, 3.3MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling graphviz dependency: \u001b[32mlibrsvg\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring librsvg--2.50.7.monterey.bottle.tar.gz\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1m/usr/local/opt/gdk-pixbuf/bin/gdk-pixbuf-query-loaders --update-cache\u001b[0m\n",
      "ðŸº  /usr/local/Cellar/librsvg/2.50.7: 48 files, 137MB\n",
      "\u001b[32m==>\u001b[0m \u001b[1mInstalling \u001b[32mgraphviz\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring graphviz--2.50.0.monterey.bottle.tar.gz\u001b[0m\n",
      "ðŸº  /usr/local/Cellar/graphviz/2.50.0: 292 files, 6.8MB\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRunning `brew cleanup graphviz`...\u001b[0m\n",
      "Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.\n",
      "Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot\n",
    "!brew install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20c804da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "#This is an alternate way of displaying your model\n",
    "#It requires you to install pydot, pydot plus and graphviz\n",
    "#In your instance type these two commands:\n",
    "# pip install pydot\n",
    "# sudo apt-get install graphviz\n",
    "#Some of those may already be part of the anaconda package installed on your GCP instance\n",
    "\n",
    "#Try adding show_shapes=True and/or show_dtype=True as args to plot_model\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ad5730",
   "metadata": {},
   "source": [
    "[Return to Top](#top)\n",
    "<a id = 'trainModel'></a>\n",
    "### B4. Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e57b3d3",
   "metadata": {},
   "source": [
    "#### Define the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c77b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at some data and labels:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "nrotate =  6\n",
    "size = 2040\n",
    "theta = np.linspace(start = 0, stop = nrotate * 2 * np.pi, num = size)\n",
    "len(theta)\n",
    "r = 1/(nrotate * 2 * np.pi) * theta\n",
    "x = r * np.cos(theta)\n",
    "y = r * np.sin(theta)\n",
    "# Toggle the below line to see the dividing line between groups\n",
    "plt.plot(x, y)\n",
    "# thickness = 1/(nrotate * 2 * np.pi) * 2 pi = 1 / nrotate\n",
    "1 / nrotate * np.random.uniform(size = 100)\n",
    "eps = 0.8\n",
    "nparts = 4\n",
    "colors = []\n",
    "for i in range(nparts):\n",
    "    colors.extend(['r']*int(size / (2*nparts)) + ['b']*int(size / (2*nparts)))\n",
    "labels = ['r']*int(size/nparts) + ['b']*int(size/nparts)+['r']*int(size/nparts) + ['b']*int(size/nparts)\n",
    "rjitter = r - eps / nrotate * np.random.uniform(size = size)\n",
    "xjitter = rjitter*np.cos(theta)\n",
    "yjitter = rjitter*np.sin(theta)\n",
    "plt.scatter(xjitter, yjitter, color = colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2fd76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Convert our data to numpy arrays with correct shapes for our model input, output\n",
    "datain = np.transpose(np.vstack([x,y]))\n",
    "labels = np.array([1 if color=='b' else 0 for color in colors]).reshape([-1,1])\n",
    "\n",
    "# Create training, eval split\n",
    "train_input, test_input, train_labels, test_labels = train_test_split(datain, labels, test_size = 0.2, \n",
    "                                                         random_state = 41,\n",
    "                                                         shuffle = True)\n",
    "# Train the model using our training input, labels\n",
    "## the validation_split arguments states that 20% of the training data is to be used\n",
    "## ...as dev data.\n",
    "model.fit(train_input, train_labels, batch_size = 400, validation_split=0.2, epochs = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d712525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the data with our test_input, test_labels\n",
    "model.evaluate(test_input, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42829063",
   "metadata": {},
   "source": [
    "[Return to Top](#top)\n",
    "<a id = 'saveModel'></a>\n",
    "### B5. Saving a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b8008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "model.save(\"./keras_qs_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e64151",
   "metadata": {},
   "source": [
    "[Return to Top](#top)\n",
    "<a id = 'reloadModel'></a>\n",
    "### B6. Reloading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea9c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that reloaded model evaluates to same score as when we saved it originally.\n",
    "model2 = keras.models.load_model(\"./keras_qs_model\")\n",
    "model2.evaluate(train_input, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee1753",
   "metadata": {},
   "source": [
    "[Return to Top](#top)\n",
    "<a id = 'functionWrapper'></a>\n",
    "## C. Defining your model inside a function to add flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63356b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to re-run your model with different settings and hyper-parameters there's a good chance you'll benefit by using a class definition.\n",
    "\n",
    "# Define parameters in a dictionary\n",
    "modelparams = dict(\n",
    "    layers = ( (200, 'relu'), (100, 'relu') ), \n",
    "    n_classes = 2, # number of output classes -- 2 for binary\n",
    "    learning_rate = 0.01, \n",
    "    output_activation = \"sigmoid\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    optimizer = \"adam\",\n",
    "    metrics = [\"sparse_categorical_accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "def basic_km(**kwargs):\n",
    "    layers = kwargs.get('layers', ((10, 'relu')) ) \n",
    "    n_classes = kwargs.get('n_classes', 2)\n",
    "    learning_rate = kwargs.get('learning_rate', 0.01)\n",
    "    output_activation = kwargs.get('output_activation', \"sigmoid\")\n",
    "    optimizer = kwargs.get('optimizer', \"adam\")\n",
    "    loss = kwargs.get('loss', \"categorical_crossentropy\")\n",
    "    metrics = kwargs.get('metrics', [\"accuracy\"])\n",
    "    \n",
    "    num_layers = len(layers)\n",
    "    \n",
    "    graph = []\n",
    "    # Define input shape\n",
    "    graph.append(keras.Input(shape=(2,)))\n",
    "    # Add hidden layers\n",
    "    for i, layer in enumerate(layers):\n",
    "        graph.append(keras.layers.Dense(layer[0], activation = layer[1], name = \"h\" + str(i+1) + \"layer\"   ))\n",
    "    # Add output layer\n",
    "    graph.append(keras.layers.Dense(n_classes, activation = output_activation, name=\"output_layer\"))\n",
    "    \n",
    "    # Define a sequential model from inputs and outputs of graph\n",
    "    model = keras.Sequential(graph)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss = loss, optimizer = optimizer, metrics = metrics)\n",
    "    return model\n",
    "\n",
    "modelFromDef = basic_km(**modelparams)\n",
    "\n",
    "# Train model \n",
    "modelFromDef.fit(train_input, train_labels, batch_size = 400, validation_split=0.2, epochs = 300)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7924fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
